# examples/simulation.py
#
# ARG PCA simulation script.
#
# This script reproduces the main simulation scenarios from the paper:
#
#   1. Single-spike, single-reference (Normal + t)
#   2. Multi-spike, multi-reference (Normal + t)
#
# It assumes:
#   - Data are generated by helpers in examples/dgps.py
#   - Subspace distances are measured by examples/metrics.py
#   - Baseline PCA subspaces are computed via argpca.utils
#   - ARG PCA subspaces are computed via argpca.pca.compute_arg_pc_subspace
#
# Running this script will write a small set of CSV summary tables under:
#   examples/results/
#
# Usage (from repo root):
#   python examples/simulation.py
#
# or (from within examples/):
#   python simulation.py
#
# The script is intended as an example / reproducibility tool and is
# not part of the public argpca API.

from __future__ import annotations

from pathlib import Path
from typing import List, Tuple

import numpy as np
import pandas as pd

# Local example helpers (resolved via the examples/ directory on sys.path)
from dgps import (
    generate_basis,
    generate_reference_vectors,
    sigma_single_spike,
    sigma_multi_spike,
    sample_normal,
    sample_t,
)
from metrics import compute_principal_angles

# Core package routines
from argpca.pca import compute_arg_pc_subspace
from argpca.utils import compute_gram_spectrum, recover_spike_directions


# Base directory for this script (…/examples)
BASE_DIR = Path(__file__).resolve().parent
RESULTS_DIR = BASE_DIR / "results"


# ---------------------------------------------------------------------------
# Internal helper: baseline PCA via GramSpectrum
# ---------------------------------------------------------------------------

def _compute_pca_subspace(
    samples: np.ndarray,
    n_components: int,
) -> np.ndarray:
    """
    Compute the top-`n_components` PCA directions using the same
    Gram-matrix machinery as ARG PCA.

    This function is used to define the **baseline PCA** subspace in the
    simulation. It deliberately mirrors the ARG implementation by working
    through the Gram matrix:

        G = (1/n) Xc Xc^T,   Xc = centered data

    and then recovering feature-space eigenvectors via the dual relation.

    Parameters
    ----------
    samples : (n, p) array_like
        Data matrix with rows = samples, columns = features.
    n_components : int
        Number of leading principal components.

    Returns
    -------
    components_pca : (n_components, p) ndarray
        Row-oriented principal directions. Each row is a unit vector in R^p,
        following the scikit-learn ``PCA.components_`` convention and the
        rest of the argpca package.
    """
    X = np.asarray(samples, dtype=float)
    if X.ndim != 2:
        raise ValueError(f"`samples` must be 2D, got {X.ndim}D.")

    spectrum = compute_gram_spectrum(X)
    U_spike, _, _ = recover_spike_directions(spectrum, n_components)
    # U_spike: (p, m) with columns = eigenvectors → transpose to (m, p)
    return U_spike.T


# ---------------------------------------------------------------------------
# Single-spike, single-reference simulation (Normal + t)
# ---------------------------------------------------------------------------

def run_simulation_single(
    p_list: List[int],
    a_list: List[float],
    n: int,
    nu: int,
    n_trials: int,
    sigma_coef: Tuple[float, float],
    master_seed: int = 725,
    results_dir: Path | None = None,
) -> None:
    """
    Run the single-spike, single-reference simulation under Normal and t
    sampling, and write summary tables (means / stds of principal angles)
    to CSV files.

    Model
    -----
    - Covariance:
        Sigma = c1 * p * e1 e1^T + c2 * I_p,
      where (e1, …, e4) are the sign-pattern basis vectors from
      ``generate_basis(p)``.

    - True spike direction:
        u1_row ∈ R^{1×p},
      returned by ``sigma_single_spike`` as a **row vector** so that it
      can be passed directly to ``compute_principal_angles``.

    - Reference vectors:
      For each a in ``a_list``, we define a single reference

        v(a) = a e1 + sqrt(1 - a^2) e2,

      and compare ARG PCA (with this reference) against baseline PCA.

    Quantities recorded
    -------------------
    For each p ∈ p_list and a ∈ a_list we compute, over n_trials:

      - principal angle between u1 and baseline PCA (top-1),
      - principal angle between u1 and ARG PCA (top-1).

    Under both:
      - Normal sampling  N(0, Sigma),
      - tν sampling      t_ν(0, Sigma).

    The mean and standard deviation across trials are saved in four CSVs:

      - single_normal_mean.csv
      - single_normal_std.csv
      - single_t_mean.csv
      - single_t_std.csv

    The row index is p (dimension), and columns correspond to:

      ["PCA", "a^2=...", "a^2=...", …].

    Parameters
    ----------
    p_list : list of int
        Dimensions p to sweep over.
    a_list : list of float
        Coefficients a defining the reference direction v(a).
    n : int
        Sample size.
    nu : int
        Degrees of freedom for the t-distribution (nu > 2).
    n_trials : int
        Number of Monte Carlo trials for each (p, a) configuration.
    sigma_coef : (float, float)
        Tuple (c1, c2) for the single-spike covariance:
          Sigma = c1 * p * e1 e1^T + c2 * I_p.
    master_seed : int, default 725
        Seed used to derive per-trial seeds (via NumPy default_rng).
    results_dir : pathlib.Path, optional
        Directory in which to save CSV files. If None, defaults to
        ``RESULTS_DIR`` (examples/results/).
    """
    if results_dir is None:
        results_dir = RESULTS_DIR
    results_dir.mkdir(parents=True, exist_ok=True)

    rng_master = np.random.default_rng(master_seed)

    # Column labels: baseline PCA + one column per a
    col_labels = ["PCA"] + [f"a^2={a**2:.2g}" for a in a_list]

    mean_normal = np.zeros((len(p_list), len(col_labels)), dtype=float)
    mean_t = np.zeros_like(mean_normal)
    std_normal = np.zeros_like(mean_normal)
    std_t = np.zeros_like(mean_normal)

    for pi, p in enumerate(p_list):
        # Σ = c1 * p * e1 e1^T + c2 * I_p,
        # u1_row : (1, p) true spike direction (row-oriented)
        Sigma, u1_row = sigma_single_spike(p=p, coefs=sigma_coef)
        u1_row = np.asarray(u1_row, dtype=float)
        if u1_row.ndim != 2 or u1_row.shape[0] != 1 or u1_row.shape[1] != p:
            raise ValueError(
                f"`sigma_single_spike` must return e1_row with shape (1, p={p}), "
                f"got {u1_row.shape}."
            )

        # Basis (for reference construction) and mean
        E = generate_basis(p)          # (4, p), rows = e1..e4
        mu = np.zeros(p, dtype=float)  # mean vector

        # Pre-generate Normal and t samples for this p
        normal_trials = []
        t_trials = []
        for _ in range(n_trials):
            seed_n = int(rng_master.integers(0, 2**31 - 1))
            seed_t = int(rng_master.integers(0, 2**31 - 1))

            Xn = sample_normal(Sigma=Sigma, n=n, mu=mu, seed=seed_n)
            Xt = sample_t(Sigma=Sigma, nu=nu, n=n, mu=mu, seed=seed_t)

            normal_trials.append(Xn)
            t_trials.append(Xt)

        # -------------------- Baseline PCA (top-1) -------------------- #
        baseline_normal_angles = np.zeros(n_trials, dtype=float)
        baseline_t_angles = np.zeros(n_trials, dtype=float)

        for i in range(n_trials):
            U_pca_normal = _compute_pca_subspace(
                samples=normal_trials[i],
                n_components=1,
            )  # (1, p)
            U_pca_t = _compute_pca_subspace(
                samples=t_trials[i],
                n_components=1,
            )  # (1, p)

            # Principal angle between true spike and PCA direction
            baseline_normal_angles[i] = compute_principal_angles(
                u1_row, U_pca_normal
            )[0]
            baseline_t_angles[i] = compute_principal_angles(
                u1_row, U_pca_t
            )[0]

        mean_normal[pi, 0] = baseline_normal_angles.mean()
        std_normal[pi, 0] = baseline_normal_angles.std(ddof=0)
        mean_t[pi, 0] = baseline_t_angles.mean()
        std_t[pi, 0] = baseline_t_angles.std(ddof=0)

        # -------------------- ARG PCA for each a -------------------- #
        for aj, a in enumerate(a_list):
            # Single reference:
            #   v(a) = a e1 + sqrt(1 - a^2) e2
            weight2 = np.sqrt(max(0.0, 1.0 - a * a))
            A = np.array([[a, weight2, 0.0, 0.0]], dtype=float)  # (1, 4)
            V_rows = generate_reference_vectors(E, A)            # (1, p)

            arg_normal_angles = np.zeros(n_trials, dtype=float)
            arg_t_angles = np.zeros(n_trials, dtype=float)

            for i in range(n_trials):
                U_arg_normal = compute_arg_pc_subspace(
                    samples=normal_trials[i],
                    reference_vectors=V_rows,
                    n_components=1,
                    orthonormal=True,
                )  # (1, p)

                U_arg_t = compute_arg_pc_subspace(
                    samples=t_trials[i],
                    reference_vectors=V_rows,
                    n_components=1,
                    orthonormal=True,
                )  # (1, p)

                arg_normal_angles[i] = compute_principal_angles(
                    u1_row, U_arg_normal
                )[0]
                arg_t_angles[i] = compute_principal_angles(
                    u1_row, U_arg_t
                )[0]

            mean_normal[pi, 1 + aj] = arg_normal_angles.mean()
            std_normal[pi, 1 + aj] = arg_normal_angles.std(ddof=0)
            mean_t[pi, 1 + aj] = arg_t_angles.mean()
            std_t[pi, 1 + aj] = arg_t_angles.std(ddof=0)

    # -------------------- Write summary CSVs -------------------- #
    index = p_list

    pd.DataFrame(mean_normal, index=index, columns=col_labels).to_csv(
        results_dir / "single_normal_mean.csv",
        index_label="p",
    )
    pd.DataFrame(std_normal, index=index, columns=col_labels).to_csv(
        results_dir / "single_normal_std.csv",
        index_label="p",
    )
    pd.DataFrame(mean_t, index=index, columns=col_labels).to_csv(
        results_dir / "single_t_mean.csv",
        index_label="p",
    )
    pd.DataFrame(std_t, index=index, columns=col_labels).to_csv(
        results_dir / "single_t_std.csv",
        index_label="p",
    )


# ---------------------------------------------------------------------------
# Multi-spike, multi-reference simulation (Normal + t)
# ---------------------------------------------------------------------------

def run_simulation_multi(
    p_list: List[int],
    n: int,
    nu: int,
    n_trials: int,
    sigma_coef: Tuple[float, float, float],
    master_seed: int = 725,
    results_dir: Path | None = None,
) -> None:
    """
    Run the multi-spike, multi-reference simulation under Normal and t
    sampling, and write summary tables to CSV files.

    Model
    -----
    - Covariance:
        Sigma = c1 * p * e1 e1^T + c2 * p * e2 e2^T + c3 * I_p,
      where (e1, e2, e3, e4) are the sign-pattern basis vectors produced
      by ``generate_basis(p)``.

    - True signal subspace:
        span{e1, e2}, represented by

            U_true ∈ R^{2×p},

      whose rows are e1 and e2. This is returned directly by
      ``sigma_multi_spike``.

    - References:
      Two reference rows v1, v2 defined as mixtures of e1,…,e4 via a
      mixing matrix A (2×4), using ``generate_reference_vectors``.

    Metrics
    -------
    For each trial, we compute principal angles between:

      - ARG 2D subspace and true 2D subspace (U_true),
      - baseline PCA 2D subspace and true 2D subspace,

    and extract the **first two principal angles** in both cases.
    For Normal and t sampling, we thus record:

      [angle(ARG, first), angle(PCA, first),
       angle(ARG, second), angle(PCA, second)].

    The mean and standard deviation over n_trials are saved in four CSVs:

      - multi_normal_mean.csv
      - multi_normal_std.csv
      - multi_t_mean.csv
      - multi_t_std.csv

    with row index p and columns:

      ["ARG1", "PCA1", "ARG2", "PCA2"].

    Parameters
    ----------
    p_list : list of int
        Dimensions p to sweep over.
    n : int
        Sample size.
    nu : int
        Degrees of freedom for the t-distribution (nu > 2).
    n_trials : int
        Number of Monte Carlo trials for each p.
    sigma_coef : (float, float, float)
        Coefficients (c1, c2, c3) for the two-spike covariance:
          Sigma = c1 * p * e1 e1^T + c2 * p * e2 e2^T + c3 * I_p.
    master_seed : int, default 725
        Seed used to derive per-trial seeds.
    results_dir : pathlib.Path, optional
        Directory to write CSV files. Defaults to ``RESULTS_DIR``.
    """
    if results_dir is None:
        results_dir = RESULTS_DIR
    results_dir.mkdir(parents=True, exist_ok=True)

    rng_master = np.random.default_rng(master_seed)

    col_labels = ["ARG1", "PCA1", "ARG2", "PCA2"]
    mean_normal = np.zeros((len(p_list), len(col_labels)), dtype=float)
    std_normal = np.zeros_like(mean_normal)
    mean_t = np.zeros_like(mean_normal)
    std_t = np.zeros_like(mean_normal)

    for pi, p in enumerate(p_list):
        # Σ = c1 * p * e1 e1^T + c2 * p * e2 e2^T + c3 * I_p
        # U_true : (2, p) with rows [e1; e2]
        Sigma, U_true = sigma_multi_spike(p=p, coefs=sigma_coef)
        U_true = np.asarray(U_true, dtype=float)
        if U_true.ndim != 2 or U_true.shape != (2, p):
            raise ValueError(
                f"`sigma_multi_spike` must return U_m with shape (2, p={p}), "
                f"got {U_true.shape}."
            )

        # Basis and references
        E = generate_basis(p)
        mu = np.zeros(p, dtype=float)

        # Define two reference vectors (rows) via mixing matrix A (2, 4)
        A = np.array(
            [
                [0.5, 0.5, 0.5, 0.5],
                [1.0 / np.sqrt(2.0), 0.0, -1.0 / np.sqrt(2.0), 0.0],
            ],
            dtype=float,
        )
        V_rows = generate_reference_vectors(E, A)  # (2, p)

        angles_normal = np.zeros((n_trials, 4), dtype=float)
        angles_t = np.zeros((n_trials, 4), dtype=float)

        for t_idx in range(n_trials):
            seed_n = int(rng_master.integers(0, 2**31 - 1))
            seed_t = int(rng_master.integers(0, 2**31 - 1))

            Xn = sample_normal(Sigma=Sigma, n=n, mu=mu, seed=seed_n)
            Xt = sample_t(Sigma=Sigma, nu=nu, n=n, mu=mu, seed=seed_t)

            # ---- Normal case ----
            U_arg_normal = compute_arg_pc_subspace(
                samples=Xn,
                reference_vectors=V_rows,
                n_components=2,
                orthonormal=True,
            )  # (2, p)

            U_pca_normal = _compute_pca_subspace(
                samples=Xn,
                n_components=2,
            )  # (2, p)

            th_arg_normal = compute_principal_angles(U_true, U_arg_normal)
            th_pca_normal = compute_principal_angles(U_true, U_pca_normal)

            angles_normal[t_idx, :] = [
                th_arg_normal[0],
                th_pca_normal[0],
                th_arg_normal[1],
                th_pca_normal[1],
            ]

            # ---- t case ----
            U_arg_t = compute_arg_pc_subspace(
                samples=Xt,
                reference_vectors=V_rows,
                n_components=2,
                orthonormal=True,
            )  # (2, p)

            U_pca_t = _compute_pca_subspace(
                samples=Xt,
                n_components=2,
            )  # (2, p)

            th_arg_t = compute_principal_angles(U_true, U_arg_t)
            th_pca_t = compute_principal_angles(U_true, U_pca_t)

            angles_t[t_idx, :] = [
                th_arg_t[0],
                th_pca_t[0],
                th_arg_t[1],
                th_pca_t[1],
            ]

        # Aggregate over trials
        mean_normal[pi, :] = angles_normal.mean(axis=0)
        std_normal[pi, :] = angles_normal.std(axis=0, ddof=0)
        mean_t[pi, :] = angles_t.mean(axis=0)
        std_t[pi, :] = angles_t.std(axis=0, ddof=0)

    # -------------------- Write summary CSVs -------------------- #
    index = p_list

    pd.DataFrame(mean_normal, index=index, columns=col_labels).to_csv(
        results_dir / "multi_normal_mean.csv",
        index_label="p",
    )
    pd.DataFrame(std_normal, index=index, columns=col_labels).to_csv(
        results_dir / "multi_normal_std.csv",
        index_label="p",
    )
    pd.DataFrame(mean_t, index=index, columns=col_labels).to_csv(
        results_dir / "multi_t_mean.csv",
        index_label="p",
    )
    pd.DataFrame(std_t, index=index, columns=col_labels).to_csv(
        results_dir / "multi_t_std.csv",
        index_label="p",
    )


# ---------------------------------------------------------------------------
# Main entry point
# ---------------------------------------------------------------------------

def main() -> None:
    """
    Run both simulation scenarios with default parameters.

    These defaults correspond roughly to the settings used in the paper
    and are chosen to be moderately heavy but still reasonably fast on
    a modern laptop (e.g., Apple Silicon MacBook Pro).

    The results are written as eight CSV files under:

        examples/results/

    See the docstrings of ``run_simulation_single`` and
    ``run_simulation_multi`` for details on the contents of each file.
    """
    # Dimensions to sweep
    p_list = [100, 200, 500, 1000, 2000]

    # Sample size and t degrees of freedom
    n = 40
    nu = 5

    # Number of Monte Carlo trials per configuration
    n_trials = 100

    # Single-spike coefficients (c1, c2) for:
    #   Sigma = c1 * p * e1 e1^T + c2 * I_p
    sigma_single = (1.0, 40.0)

    # Multi-spike coefficients (c1, c2, c3) for:
    #   Sigma = c1 * p * e1 e1^T + c2 * p * e2 e2^T + c3 * I_p
    sigma_multi = (2.0, 1.0, 40.0)

    # Reference mixing coefficients a (for single-spike scenario):
    #   v(a) = a e1 + sqrt(1 - a^2) e2
    a_list = [0.0, 0.5, 1.0 / np.sqrt(2.0), np.sqrt(3.0) / 2.0, 1.0]

    print("Running single-spike, single-reference simulation...")
    run_simulation_single(
        p_list=p_list,
        a_list=a_list,
        n=n,
        nu=nu,
        n_trials=n_trials,
        sigma_coef=sigma_single,
        master_seed=725,
        results_dir=RESULTS_DIR,
    )
    print(f"✓ Single-spike results written under: {RESULTS_DIR}")

    print("Running multi-spike, multi-reference simulation...")
    run_simulation_multi(
        p_list=p_list,
        n=n,
        nu=nu,
        n_trials=n_trials,
        sigma_coef=sigma_multi,
        master_seed=725,
        results_dir=RESULTS_DIR,
    )
    print(f"✓ Multi-spike results written under: {RESULTS_DIR}")


if __name__ == "__main__":
    main()